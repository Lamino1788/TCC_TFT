{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Lamino1788/TCC_TFT/blob/main/Predictions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOXVzN05kxt6",
        "outputId": "622b609f-dcd8-4f4d-d1b4-4adc512f48f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch-forecasting\n",
            "  Downloading pytorch_forecasting-1.0.0-py3-none-any.whl (140 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.4/140.4 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fastapi>=0.80 (from pytorch-forecasting)\n",
            "  Downloading fastapi-0.104.1-py3-none-any.whl (92 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.9/92.9 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting lightning<3.0.0,>=2.0.0 (from pytorch-forecasting)\n",
            "  Downloading lightning-2.1.2-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m76.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from pytorch-forecasting) (3.7.1)\n",
            "Collecting optuna<4.0.0,>=3.1.0 (from pytorch-forecasting)\n",
            "  Downloading optuna-3.4.0-py3-none-any.whl (409 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m409.6/409.6 kB\u001b[0m \u001b[31m37.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas<=3.0.0,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-forecasting) (1.5.3)\n",
            "Collecting pytorch-optimizer<3.0.0,>=2.5.1 (from pytorch-forecasting)\n",
            "  Downloading pytorch_optimizer-2.12.0-py3-none-any.whl (155 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.8/155.8 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn<2.0,>=1.2 in /usr/local/lib/python3.10/dist-packages (from pytorch-forecasting) (1.2.2)\n",
            "Requirement already satisfied: scipy<2.0,>=1.8 in /usr/local/lib/python3.10/dist-packages (from pytorch-forecasting) (1.11.3)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.10/dist-packages (from pytorch-forecasting) (0.14.0)\n",
            "Requirement already satisfied: torch<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-forecasting) (2.1.0+cu118)\n",
            "Requirement already satisfied: anyio<4.0.0,>=3.7.1 in /usr/local/lib/python3.10/dist-packages (from fastapi>=0.80->pytorch-forecasting) (3.7.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from fastapi>=0.80->pytorch-forecasting) (1.10.13)\n",
            "Collecting starlette<0.28.0,>=0.27.0 (from fastapi>=0.80->pytorch-forecasting)\n",
            "  Downloading starlette-0.27.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-extensions>=4.8.0 (from fastapi>=0.80->pytorch-forecasting)\n",
            "  Downloading typing_extensions-4.8.0-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: PyYAML<8.0,>=5.4 in /usr/local/lib/python3.10/dist-packages (from lightning<3.0.0,>=2.0.0->pytorch-forecasting) (6.0.1)\n",
            "Requirement already satisfied: fsspec[http]<2025.0,>2021.06.0 in /usr/local/lib/python3.10/dist-packages (from lightning<3.0.0,>=2.0.0->pytorch-forecasting) (2023.6.0)\n",
            "Collecting lightning-utilities<2.0,>=0.8.0 (from lightning<3.0.0,>=2.0.0->pytorch-forecasting)\n",
            "  Downloading lightning_utilities-0.10.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from lightning<3.0.0,>=2.0.0->pytorch-forecasting) (1.23.5)\n",
            "Requirement already satisfied: packaging<25.0,>=20.0 in /usr/local/lib/python3.10/dist-packages (from lightning<3.0.0,>=2.0.0->pytorch-forecasting) (23.2)\n",
            "Collecting torchmetrics<3.0,>=0.7.0 (from lightning<3.0.0,>=2.0.0->pytorch-forecasting)\n",
            "  Downloading torchmetrics-1.2.0-py3-none-any.whl (805 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m805.2/805.2 kB\u001b[0m \u001b[31m56.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm<6.0,>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from lightning<3.0.0,>=2.0.0->pytorch-forecasting) (4.66.1)\n",
            "Collecting pytorch-lightning (from lightning<3.0.0,>=2.0.0->pytorch-forecasting)\n",
            "  Downloading pytorch_lightning-2.1.2-py3-none-any.whl (776 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m776.9/776.9 kB\u001b[0m \u001b[31m52.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting alembic>=1.5.0 (from optuna<4.0.0,>=3.1.0->pytorch-forecasting)\n",
            "  Downloading alembic-1.12.1-py3-none-any.whl (226 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.8/226.8 kB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting colorlog (from optuna<4.0.0,>=3.1.0->pytorch-forecasting)\n",
            "  Downloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna<4.0.0,>=3.1.0->pytorch-forecasting) (2.0.23)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas<=3.0.0,>=1.3.0->pytorch-forecasting) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<=3.0.0,>=1.3.0->pytorch-forecasting) (2023.3.post1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2.0,>=1.2->pytorch-forecasting) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2.0,>=1.2->pytorch-forecasting) (3.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.0.0->pytorch-forecasting) (3.13.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.0.0->pytorch-forecasting) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.0.0->pytorch-forecasting) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.0.0->pytorch-forecasting) (3.1.2)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.0.0->pytorch-forecasting) (2.1.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pytorch-forecasting) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pytorch-forecasting) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pytorch-forecasting) (4.44.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pytorch-forecasting) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pytorch-forecasting) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pytorch-forecasting) (3.1.1)\n",
            "Requirement already satisfied: patsy>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from statsmodels->pytorch-forecasting) (0.5.3)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna<4.0.0,>=3.1.0->pytorch-forecasting)\n",
            "  Downloading Mako-1.3.0-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0.0,>=3.7.1->fastapi>=0.80->pytorch-forecasting) (3.4)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0.0,>=3.7.1->fastapi>=0.80->pytorch-forecasting) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0.0,>=3.7.1->fastapi>=0.80->pytorch-forecasting) (1.1.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<2025.0,>2021.06.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (2.31.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<2025.0,>2021.06.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (3.8.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities<2.0,>=0.8.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (67.7.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.5.2->statsmodels->pytorch-forecasting) (1.16.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna<4.0.0,>=3.1.0->pytorch-forecasting) (3.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch<3.0.0,>=2.0.0->pytorch-forecasting) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch<3.0.0,>=2.0.0->pytorch-forecasting) (1.3.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (3.3.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (1.3.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]<2025.0,>2021.06.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]<2025.0,>2021.06.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (2023.7.22)\n",
            "Installing collected packages: typing-extensions, Mako, colorlog, starlette, lightning-utilities, torchmetrics, pytorch-optimizer, fastapi, alembic, pytorch-lightning, optuna, lightning, pytorch-forecasting\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.5.0\n",
            "    Uninstalling typing_extensions-4.5.0:\n",
            "      Successfully uninstalled typing_extensions-4.5.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.8.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Mako-1.3.0 alembic-1.12.1 colorlog-6.7.0 fastapi-0.104.1 lightning-2.1.2 lightning-utilities-0.10.0 optuna-3.4.0 pytorch-forecasting-1.0.0 pytorch-lightning-2.1.2 pytorch-optimizer-2.12.0 starlette-0.27.0 torchmetrics-1.2.0 typing-extensions-4.8.0\n",
            "Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.10/dist-packages (2.1.2)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (1.23.5)\n",
            "Requirement already satisfied: torch>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (2.1.0+cu118)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (4.66.1)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (6.0.1)\n",
            "Requirement already satisfied: fsspec[http]>2021.06.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (2023.6.0)\n",
            "Requirement already satisfied: torchmetrics>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (1.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (23.2)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (4.8.0)\n",
            "Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (0.10.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>2021.06.0->pytorch-lightning) (2.31.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>2021.06.0->pytorch-lightning) (3.8.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->pytorch-lightning) (67.7.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->pytorch-lightning) (3.13.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->pytorch-lightning) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->pytorch-lightning) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->pytorch-lightning) (3.1.2)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->pytorch-lightning) (2.1.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (3.3.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.12.0->pytorch-lightning) (2.1.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.12.0->pytorch-lightning) (1.3.0)\n",
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.10/dist-packages (0.2.31)\n",
            "Requirement already satisfied: pandas>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from yfinance) (1.5.3)\n",
            "Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.10/dist-packages (from yfinance) (1.23.5)\n",
            "Requirement already satisfied: requests>=2.31 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2.31.0)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.10/dist-packages (from yfinance) (0.0.11)\n",
            "Requirement already satisfied: lxml>=4.9.1 in /usr/local/lib/python3.10/dist-packages (from yfinance) (4.9.3)\n",
            "Requirement already satisfied: appdirs>=1.4.4 in /usr/local/lib/python3.10/dist-packages (from yfinance) (1.4.4)\n",
            "Requirement already satisfied: pytz>=2022.5 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2023.3.post1)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2.3.8)\n",
            "Requirement already satisfied: peewee>=3.16.2 in /usr/local/lib/python3.10/dist-packages (from yfinance) (3.17.0)\n",
            "Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.10/dist-packages (from yfinance) (4.11.2)\n",
            "Requirement already satisfied: html5lib>=1.1 in /usr/local/lib/python3.10/dist-packages (from yfinance) (1.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (2.5)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.10/dist-packages (from html5lib>=1.1->yfinance) (1.16.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from html5lib>=1.1->yfinance) (0.5.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.0->yfinance) (2.8.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (2023.7.22)\n"
          ]
        }
      ],
      "source": [
        "!pip install pytorch-forecasting\n",
        "!pip install pytorch-lightning\n",
        "!pip install yfinance\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Sll-Cemmk1VU"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchmetrics import Metric\n",
        "\n",
        "from pytorch_forecasting import TemporalFusionTransformer, TimeSeriesDataSet\n",
        "from pytorch_forecasting.data import GroupNormalizer\n",
        "from pytorch_forecasting.metrics import SMAPE, QuantileLoss, MAPE\n",
        "from pytorch_forecasting.models.temporal_fusion_transformer.tuning import optimize_hyperparameters\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import pytorch_lightning as pl\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "from pytorch_forecasting import Baseline, TemporalFusionTransformer, TimeSeriesDataSet\n",
        "from pytorch_forecasting.data import GroupNormalizer\n",
        "from pytorch_forecasting.metrics import MAE, SMAPE, PoissonLoss, QuantileLoss, RMSE\n",
        "\n",
        "\n",
        "import warnings\n",
        "from sklearn.exceptions import DataConversionWarning\n",
        "\n",
        "from pytorch_lightning.tuner import Tuner\n",
        "from lightning.pytorch.callbacks import EarlyStopping, LearningRateMonitor\n",
        "from pytorch_lightning.loggers import TensorBoardLogger\n",
        "\n",
        "warnings.filterwarnings(action='ignore', category=UserWarning)\n",
        "\n",
        "import logging\n",
        "import datetime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_NxtIFEQCpkR",
        "outputId": "0457b50b-655c-49cb-a761-c5149766ce74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "hz8k-lpKk5CS"
      },
      "outputs": [],
      "source": [
        "max_encoder_length = 126\n",
        "max_prediction_length = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "JnHpwe3slmev"
      },
      "outputs": [],
      "source": [
        "class MyMAE(Metric):\n",
        "  global max_prediction_length\n",
        "  def __init__(self):\n",
        "      super().__init__(dist_sync_on_step=False)\n",
        "      self.add_state(\"loss\", default=torch.tensor(0.0), dist_reduce_fx=\"sum\")\n",
        "\n",
        "  def update(self, preds, target):\n",
        "      # Ensure the inputs are tensors\n",
        "      # Compute cumulative product (remove `dim=1` argument)\n",
        "\n",
        "      preds = preds.view(int(len(preds)/max_prediction_length),max_prediction_length)\n",
        "      preds = preds.sum(dim=1)\n",
        "      target = target.view(int(len(target)/max_prediction_length),max_prediction_length)\n",
        "      target = target.sum(dim=1)\n",
        "\n",
        "      mae = abs(preds - target).mean()\n",
        "\n",
        "      self.loss +=  mae\n",
        "\n",
        "  def compute(self):\n",
        "      # Compute final metric\n",
        "      return self.loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "lyNUhOmok_Ep"
      },
      "outputs": [],
      "source": [
        "def add_macd(df, short_period=12, long_period=26, signal_period=9): #Moving Average Convergence Divergence\n",
        "    exp1 = df['Close'].ewm(span=short_period, adjust=False).mean()\n",
        "    exp2 = df['Close'].ewm(span=long_period, adjust=False).mean()\n",
        "    macd = exp1 - exp2\n",
        "    signal = macd.ewm(span=signal_period, adjust=False).mean()\n",
        "    df['MACD'] = macd\n",
        "    df['MACD_Signal'] = signal\n",
        "    return df\n",
        "\n",
        "def add_rsi(df, period=30): #Relative Strength Index\n",
        "    delta = df['Close'].diff()\n",
        "    delta = delta[1:]\n",
        "    up, down = delta.copy(), delta.copy()\n",
        "    up[up < 0] = 0\n",
        "    down[down > 0] = 0\n",
        "\n",
        "    for period in [7, 14, 22, 30, 60]:\n",
        "      average_gain = up.rolling(window=period).mean()\n",
        "      average_loss = abs(down.rolling(window=period).mean())\n",
        "      rs = average_gain / average_loss\n",
        "      rsi = 100.0 - (100.0 / (1.0 + rs))\n",
        "\n",
        "      df[f'RSI_{period}'] = rsi\n",
        "    return df\n",
        "\n",
        "def encode_cyclical(df, col, max_val):\n",
        "    df[col] = np.cos(2 * np.pi * df[col]/max_val)\n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "5cd1477bk6rg"
      },
      "outputs": [],
      "source": [
        "# SPX = 'USDBRL=X' # Dollar Future\n",
        "def make_SPX_hist(SPX):\n",
        "  # SPX = 'ES=F'\n",
        "  global unknown_reals\n",
        "  SPX_data = yf.Ticker(SPX)\n",
        "\n",
        "  # SPX_hist = SPX_data.history(start = datetime.datetime(2000,1,1), end = datetime.datetime(2023,7,18))\n",
        "  SPX_hist = SPX_data.history(start = datetime.datetime(2000,1,1), end = datetime.datetime(2023,11,13))\n",
        "  SPX_hist.index = pd.to_datetime(SPX_hist.index, format='%y-%m-%d').strftime('%Y-%m-%d')\n",
        "  SPX_hist = SPX_hist[['Close']]\n",
        "\n",
        "  tickers=[\n",
        "      # 'ZF=F', 'ZT=F', 'ZB=F', \"ZN=F\",\n",
        "      # \"ES=F\", \"YM=F\", \"NQ=F\", #\"RTY=F\",\n",
        "      # \"GC=F\", \"SI=F\", \"ZC=F\", \"CL=F\", \"SB=F\", \"CT=F\",\n",
        "      \"EUR=X\", \"JPY=X\", \"GBP=X\", 'BRL=X', \"MXN=X\", \"CAD=X\"\n",
        "  ]\n",
        "  # tickers.remove(SPX)\n",
        "\n",
        "  for ticker in tickers:\n",
        "    data = yf.Ticker(ticker)\n",
        "    hist = data.history(start = datetime.datetime(2000,1,1), end = datetime.datetime(2023,11,13))\n",
        "    hist.index = pd.to_datetime(hist.index, format='%y-%m-%d').strftime('%Y-%m-%d')\n",
        "    SPX_hist = SPX_hist.join(pd.DataFrame(hist['Close']), rsuffix=f'_{ticker}')\n",
        "\n",
        "  SPX_hist = np.log(SPX_hist / SPX_hist.shift(1))\n",
        "  SPX_hist['Close_prediction'] = SPX_hist['Close'].shift(max_prediction_length).fillna(0)\n",
        "  SPX_hist['Close_encoder'] = SPX_hist['Close'].shift(max_encoder_length).fillna(0)\n",
        "  SPX_hist = SPX_hist.fillna(0).drop(list(SPX_hist.index)[0])\n",
        "\n",
        "  SPX_hist.reset_index(inplace=True)\n",
        "  SPX_hist.rename(columns={'date': 'Date'},inplace=True)\n",
        "\n",
        "  for i in SPX_hist.index:\n",
        "    SPX_hist.loc[i,'Rolling_Avg_22d'] = SPX_hist.loc[i-30:i-1, 'Close'].mean()\n",
        "    SPX_hist.loc[i,'Rolling_Vol_22d'] = SPX_hist.loc[i-30:i-1, 'Close'].std()\n",
        "\n",
        "  SPX_hist['Exponential_Avg'] = SPX_hist.Close.ewm(span=max_encoder_length).mean()\n",
        "  SPX_hist = add_macd(SPX_hist)\n",
        "  SPX_hist = add_rsi(SPX_hist)\n",
        "\n",
        "  SPX_hist.fillna(0)\n",
        "  SPX_hist.loc[SPX_hist.Rolling_Avg_22d == 0, 'Rolling_Avg_22d'] = SPX_hist.loc[SPX_hist.Rolling_Avg_22d == 0, 'Close']\n",
        "\n",
        "  unknown_reals = list(SPX_hist.columns)[1:]\n",
        "\n",
        "  SPX_hist['Ticker'] = SPX\n",
        "  # SPX_hist.index = pd.to_datetime(SPX_hist.Date)\n",
        "  SPX_hist.index = SPX_hist.index.astype(int)\n",
        "  SPX_hist['Time_Fix'] = SPX_hist.index\n",
        "\n",
        "  SPX_hist['Year'] = SPX_hist.Date.str.split('-').str[0].astype(int)\n",
        "  SPX_hist['Month'] = SPX_hist.Date.str.split('-').str[1].astype(int)\n",
        "  SPX_hist['Day'] = SPX_hist.Date.str.split('-').str[2].astype(int)\n",
        "\n",
        "  SPX_hist = encode_cyclical(SPX_hist, 'Month', 12)\n",
        "  SPX_hist = encode_cyclical(SPX_hist, 'Day', 31)\n",
        "\n",
        "  return SPX_hist\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SPX = \"BRL\"\n",
        "tickers=[\n",
        "      # 'ZF=F', 'ZT=F', 'ZB=F', \"ZN=F\",\n",
        "      # \"ES=F\"#, \"YM=F\", \"NQ=F\", #\"RTY=F\",\n",
        "      # \"GC=F\", \"SI=F\", \"ZC=F\", \"CL=F\", \"SB=F\", \"CT=F\",\n",
        "      # \"EUR=X\"#, \"JPY=X\", \"GBP=X\", 'BRL=X', \"MXN=X\", \"CAD=X\"\n",
        "  ]\n",
        "\n",
        "tickers = [\"BRL=X\"]\n",
        "SPX_hist = pd.DataFrame()\n",
        "for ticker in tickers:\n",
        "  print(ticker)\n",
        "  ticker_hist = make_SPX_hist(ticker)\n",
        "  SPX_hist = pd.concat([SPX_hist,ticker_hist],axis=0)\n",
        "  # SPX_hist = SPX_hist.sort_values(by=\"Time_Fix\")\n",
        "# SPX_hist.fillna(method = \"ffill\", inplace=True)\n",
        "# SPX = \"ES=F\"\n",
        "# tmp2 = make_SPX_hist(SPX)\n",
        "# SPX_hist = pd.concat([tmp,tmp2],axis=0)\n",
        "# SPX_hist = SPX_hist.sort_values(by=\"Time_Fix\")"
      ],
      "metadata": {
        "id": "MBsgBbsbrVvP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a3fe9cd-ccb1-41fe-c584-78677c9941b4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BRL=X\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SPX_hist.dropna(inplace=True)\n"
      ],
      "metadata": {
        "id": "V8ZcsOPokJcf"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "v-0_ZyJElEn0"
      },
      "outputs": [],
      "source": [
        "high = SPX_hist.Time_Fix.max()*0.85\n",
        "low = SPX_hist.Time_Fix.max()*0.7\n",
        "\n",
        "# validation = SPX_hist.loc[(SPX_hist.Time_Fix < high) & (SPX_hist.Time_Fix > low)].reset_index(drop=True)\n",
        "# test = SPX_hist.loc[(SPX_hist.Time_Fix > high)].reset_index(drop=True)\n",
        "# validation = pd.concat([validation, test.iloc[:max_encoder_length]],axis=0).reset_index(drop=True)\n",
        "# base = SPX_hist.loc[SPX_hist.Time_Fix < low].reset_index(drop=True)\n",
        "validation = SPX_hist.loc[(SPX_hist.Year < 2020) & (SPX_hist.Year > 2016)].reset_index(drop=True)\n",
        "test = SPX_hist.loc[(SPX_hist.Year > 2019)].reset_index(drop=True)\n",
        "validation = pd.concat([validation, test.iloc[:max_encoder_length]],axis=0).reset_index(drop=True)\n",
        "base = SPX_hist.loc[SPX_hist.Year < 2016].reset_index(drop=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "53HZR4m3lF6P"
      },
      "outputs": [],
      "source": [
        "training = TimeSeriesDataSet(\n",
        "    base,\n",
        "    time_idx=\"Time_Fix\",\n",
        "    target=\"Close\",\n",
        "    group_ids=[\"Ticker\"],\n",
        "    max_encoder_length=max_encoder_length,\n",
        "    max_prediction_length=max_prediction_length,\n",
        "    static_categoricals=[\"Ticker\"],\n",
        "    time_varying_known_reals=['Month', 'Day'],\n",
        "    time_varying_unknown_reals=unknown_reals,\n",
        "    add_relative_time_idx=True,\n",
        "    add_target_scales=True,\n",
        "    add_encoder_length=True,\n",
        "    min_encoder_length=max_encoder_length // 2,\n",
        "    allow_missing_timesteps=True\n",
        ")\n",
        "\n",
        "val = TimeSeriesDataSet(\n",
        "    validation,\n",
        "    time_idx=\"Time_Fix\",\n",
        "    target=\"Close\",\n",
        "    group_ids=[\"Ticker\"],\n",
        "    max_encoder_length=max_encoder_length,\n",
        "    max_prediction_length=max_prediction_length,\n",
        "    static_categoricals=[\"Ticker\"],\n",
        "    time_varying_known_reals=['Month', 'Day'],\n",
        "    time_varying_unknown_reals=unknown_reals,\n",
        "    add_relative_time_idx=True,\n",
        "    add_target_scales=True,\n",
        "    add_encoder_length=True,\n",
        "    min_encoder_length=max_encoder_length // 2,\n",
        "    allow_missing_timesteps=True\n",
        ")\n",
        "\n",
        "test_set = TimeSeriesDataSet(\n",
        "    test,\n",
        "    time_idx=\"Time_Fix\",\n",
        "    target=\"Close\",\n",
        "    group_ids=[\"Ticker\"],\n",
        "    max_encoder_length=max_encoder_length,\n",
        "    max_prediction_length=max_prediction_length,\n",
        "    static_categoricals=[\"Ticker\"],\n",
        "    time_varying_known_reals=['Month', 'Day'],\n",
        "    time_varying_unknown_reals=unknown_reals,\n",
        "    add_relative_time_idx=True,\n",
        "    add_target_scales=True,\n",
        "    add_encoder_length=True,\n",
        "    min_encoder_length=max_encoder_length // 2,\n",
        "    allow_missing_timesteps=True\n",
        "\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "BFsXyqw6lH2i"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "train_dataloader = training.to_dataloader(train=True, batch_size=batch_size, num_workers=0)\n",
        "val_dataloader = val.to_dataloader(train=False, batch_size=batch_size*10, num_workers=0)\n",
        "test_dataloader = test_set.to_dataloader(train=False, batch_size=batch_size*10, num_workers=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XjnBxHRQljZ1",
        "outputId": "3cb4a16f-5f18-4e32-fb4a-660a09234f8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-11-21 21:01:05,690] Using an existing study with name 'Currencies_Study' instead of creating a new one.\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "import optuna\n",
        "from optuna.pruners import MedianPruner\n",
        "from pytorch_lightning.callbacks import EarlyStopping\n",
        "import lightning.pytorch as pl\n",
        "\n",
        "pruner = MedianPruner(n_startup_trials=1, n_warmup_steps=5, interval_steps=1)\n",
        "storage = 'sqlite:////content/drive/MyDrive/All_Round_Study.db'\n",
        "study = optuna.create_study(pruner=pruner, storage=storage, direction=\"minimize\", study_name='Currencies_Study', load_if_exists=True)\n",
        "best_params = study.best_trial.params\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "qCWqSijIlgvL"
      },
      "outputs": [],
      "source": [
        "best_tft = TemporalFusionTransformer.from_dataset(\n",
        "        training,  # your training dataset\n",
        "        learning_rate=best_params['learning_rate'],\n",
        "        hidden_size=best_params['hidden_size'],\n",
        "        attention_head_size=4,\n",
        "        dropout=best_params['dropout'],\n",
        "        hidden_continuous_size=best_params['hidden_continuous_size'],\n",
        "        output_size=1,  # your output size\n",
        "        loss=MyMAE(),\n",
        "        log_interval=10,\n",
        "        reduce_on_plateau_patience=4,\n",
        "        lstm_layers=2,\n",
        "        log_val_interval=10,\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "bowMGU4Eg3KP"
      },
      "outputs": [],
      "source": [
        "def calculate_sharpe(test: pd.DataFrame, best_tft, max_encoder_length, max_prediction_length):\n",
        "    total, bench = 1, 1\n",
        "    j = 0\n",
        "    signal_list, returns, pct = [], [], []\n",
        "\n",
        "    test = test.sort_values([\"Date\", \"Ticker\"])\n",
        "    output = {}\n",
        "    for ticker_out in test.Ticker.unique():\n",
        "      aux_df = test.loc[test.Ticker == ticker_out]\n",
        "      indices = aux_df.iloc[max_encoder_length+max_prediction_length:].Time_Fix\n",
        "      for i in indices:\n",
        "        # try:\n",
        "        rolling_df = aux_df.loc[aux_df.Time_Fix.isin(list(range(i-max_encoder_length-max_prediction_length, i)))]\n",
        "        if j == max_prediction_length:\n",
        "            j = 0\n",
        "        if j == 0:\n",
        "            test_predictions = best_tft.predict(rolling_df, mode=\"raw\", return_x=True)\n",
        "            counter = 0\n",
        "            for ticker in rolling_df.Ticker.unique():\n",
        "                if ticker == ticker_out:\n",
        "                    pred = test_predictions.output.prediction[counter].cpu().numpy().cumsum()[-1]\n",
        "                    if ticker not in output.keys():\n",
        "                        output[ticker] = [pred]\n",
        "                        output[ticker + \"_Real\"] = [rolling_df[\"Close_\" + ticker].iloc[-max_prediction_length]]\n",
        "                        output[ticker + \"_Date\"] = [rolling_df.loc[rolling_df.Ticker == ticker].Date.iloc[-max_prediction_length]]\n",
        "                    else:\n",
        "                        output[ticker] = output[ticker] + [pred]\n",
        "                        output[ticker + \"_Real\"] = output[ticker + \"_Real\"] + [rolling_df[\"Close_\" + ticker].iloc[-max_prediction_length]]\n",
        "                        output[ticker + \"_Date\"] = output[ticker + \"_Date\"] + [rolling_df.loc[rolling_df.Ticker == ticker].Date.iloc[-max_prediction_length]]\n",
        "                    counter = counter + 1\n",
        "            j += 1\n",
        "        else:\n",
        "            rolling_df = test.loc[test.Time_Fix.isin(list(range(i-max_encoder_length-max_prediction_length, i)))]\n",
        "            counter = 0\n",
        "            for ticker in rolling_df.Ticker.unique():\n",
        "                if ticker == ticker_out:\n",
        "                    if ticker in output.keys():\n",
        "                        output[ticker + \"_Real\"] = output[ticker + \"_Real\"] + [rolling_df[\"Close_\" + ticker].iloc[-max_prediction_length]]\n",
        "                        output[ticker + \"_Date\"] = output[ticker + \"_Date\"] + [rolling_df.loc[rolling_df.Ticker == ticker].Date.iloc[-max_prediction_length]]\n",
        "                        output[ticker] = output[ticker] + [output[ticker][-1]]\n",
        "                counter = counter + 1\n",
        "                j += 1\n",
        "        # except:\n",
        "        #     continue\n",
        "\n",
        "    return output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "IRK5YnE1SKSj"
      },
      "outputs": [],
      "source": [
        "pd.options.mode.chained_assignment = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "TtrpSbLlQP8y"
      },
      "outputs": [],
      "source": [
        "name = \"BRL\"\n",
        "version = f'{name}.pkl'\n",
        "now = SPX"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_model = f\"/content/drive/MyDrive/TCC/Best_Models/{SPX}/{now}/Seeds/0.pth\"\n",
        "best_tft.load_state_dict(torch.load(path_to_model, map_location=torch.device('cpu')))\n",
        "pred = calculate_sharpe(validation, best_tft, max_encoder_length, max_prediction_length)"
      ],
      "metadata": {
        "id": "aComz2qRycZ2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e385768-7bae-40d4-cd10-fa4802a105de"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: Missing logger folder: /content/lightning_logs\n",
            "WARNING:lightning.pytorch.loggers.tensorboard:Missing logger folder: /content/lightning_logs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# with open(f\"/content/drive/MyDrive/TCC/Best_Models/Best_Results/{SPX}/{version}\", \"wb\") as f:\n",
        "#       pickle.dump(pred, f)"
      ],
      "metadata": {
        "id": "LLGmmP-fzQQ6"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "d9hXf9mQX71l"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  with open(f\"/content/drive/MyDrive/TCC/Best_Models/Best_Results/{SPX}/{version}\", \"rb\") as f:\n",
        "      results = pickle.load(f)\n",
        "      # results = {0:[]}\n",
        "\n",
        "except:\n",
        "  results = {0:[]}\n",
        "  pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "v3iN4oL7adxm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f50ef3a-703e-4d54-9fbe-13f5e9319ac1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys([0])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "results.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "mINN_3Okg5BJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf0ed9d9-7026-418e-b94f-b90b44a277e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/TCC/Best_Models/BRL/BRL/Seeds/0.pth\n",
            "/content/drive/MyDrive/TCC/Best_Models/BRL/BRL/Seeds/1.pth\n",
            "/content/drive/MyDrive/TCC/Best_Models/BRL/BRL/Seeds/2.pth\n",
            "/content/drive/MyDrive/TCC/Best_Models/BRL/BRL/Seeds/3.pth\n",
            "/content/drive/MyDrive/TCC/Best_Models/BRL/BRL/Seeds/4.pth\n",
            "/content/drive/MyDrive/TCC/Best_Models/BRL/BRL/Seeds/5.pth\n",
            "/content/drive/MyDrive/TCC/Best_Models/BRL/BRL/Seeds/6.pth\n",
            "/content/drive/MyDrive/TCC/Best_Models/BRL/BRL/Seeds/7.pth\n",
            "/content/drive/MyDrive/TCC/Best_Models/BRL/BRL/Seeds/8.pth\n",
            "/content/drive/MyDrive/TCC/Best_Models/BRL/BRL/Seeds/9.pth\n",
            "/content/drive/MyDrive/TCC/Best_Models/BRL/BRL/Seeds/10.pth\n",
            "/content/drive/MyDrive/TCC/Best_Models/BRL/BRL/Seeds/11.pth\n",
            "/content/drive/MyDrive/TCC/Best_Models/BRL/BRL/Seeds/12.pth\n",
            "/content/drive/MyDrive/TCC/Best_Models/BRL/BRL/Seeds/13.pth\n",
            "/content/drive/MyDrive/TCC/Best_Models/BRL/BRL/Seeds/14.pth\n",
            "/content/drive/MyDrive/TCC/Best_Models/BRL/BRL/Seeds/15.pth\n",
            "/content/drive/MyDrive/TCC/Best_Models/BRL/BRL/Seeds/16.pth\n",
            "/content/drive/MyDrive/TCC/Best_Models/BRL/BRL/Seeds/17.pth\n",
            "/content/drive/MyDrive/TCC/Best_Models/BRL/BRL/Seeds/18.pth\n",
            "/content/drive/MyDrive/TCC/Best_Models/BRL/BRL/Seeds/19.pth\n",
            "/content/drive/MyDrive/TCC/Best_Models/BRL/BRL/Seeds/20.pth\n",
            "/content/drive/MyDrive/TCC/Best_Models/BRL/BRL/Seeds/21.pth\n",
            "/content/drive/MyDrive/TCC/Best_Models/BRL/BRL/Seeds/22.pth\n",
            "/content/drive/MyDrive/TCC/Best_Models/BRL/BRL/Seeds/23.pth\n",
            "/content/drive/MyDrive/TCC/Best_Models/BRL/BRL/Seeds/24.pth\n"
          ]
        }
      ],
      "source": [
        "for i in range(0,25):\n",
        "  try:\n",
        "    path_to_model = f\"/content/drive/MyDrive/TCC/Best_Models/{SPX}/{now}/Seeds/{i}.pth\"\n",
        "    print(path_to_model)\n",
        "\n",
        "    best_tft.load_state_dict(torch.load(path_to_model, map_location=torch.device('cpu')))\n",
        "    pred = calculate_sharpe(validation, best_tft, max_encoder_length, max_prediction_length)\n",
        "    results[i] = pred\n",
        "\n",
        "    with open(f\"/content/drive/MyDrive/TCC/Best_Models/Best_Results/New_Results/{SPX}/{version}\", \"wb\") as f:\n",
        "      pickle.dump(results, f)\n",
        "  except:\n",
        "    continue\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "version = f'{name}Test.pkl'"
      ],
      "metadata": {
        "id": "11MxsWG9niiq"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0,25):\n",
        "  try:\n",
        "    path_to_model = f\"/content/drive/MyDrive/TCC/Best_Models/{SPX}/{now}/Seeds/{i}.pth\"\n",
        "    print(path_to_model)\n",
        "\n",
        "    best_tft.load_state_dict(torch.load(path_to_model, map_location=torch.device('cpu')))\n",
        "    pred = calculate_sharpe(test, best_tft, max_encoder_length, max_prediction_length)\n",
        "    results[i] = pred\n",
        "\n",
        "    with open(f\"/content/drive/MyDrive/TCC/Best_Models/Best_Results/New_Results/{SPX}/{version}\", \"wb\") as f:\n",
        "      pickle.dump(results, f)\n",
        "  except:\n",
        "    continue\n"
      ],
      "metadata": {
        "id": "qu9_Qbg110UH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "085b9034-9a4c-4d7a-b0e3-fc85bf3c6a59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/TCC/Best_Models/BRL/BRL/Seeds/0.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jvfGIWLgfx1C"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}